"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[3018],{7814(n,e,r){r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-2-sensor-simulation","title":"Chapter 5 - Sensor Simulation and Integration","description":"Camera Sensor Simulation","source":"@site/docs/module-2-sensor-simulation.md","sourceDirName":".","slug":"/module-2-sensor-simulation","permalink":"/docs/module-2-sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-sensor-simulation.md","tags":[],"version":"current","frontMatter":{"id":"module-2-sensor-simulation","title":"Chapter 5 - Sensor Simulation and Integration","sidebar_label":"Chapter 5 - Sensor Simulation and Integration"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4 - Robot Modeling and Physics","permalink":"/docs/module-2-robot-modeling-physics"},"next":{"title":"Chapter 6 - Virtual Testing and Validation","permalink":"/docs/module-2-virtual-testing"}}');var t=r(4848),i=r(8453);const o={id:"module-2-sensor-simulation",title:"Chapter 5 - Sensor Simulation and Integration",sidebar_label:"Chapter 5 - Sensor Simulation and Integration"},s="Chapter 5: Sensor Simulation and Integration",l={},c=[{value:"Camera Sensor Simulation",id:"camera-sensor-simulation",level:2},{value:"Camera Simulation in Gazebo",id:"camera-simulation-in-gazebo",level:3},{value:"Camera Simulation in Unity",id:"camera-simulation-in-unity",level:3},{value:"LIDAR Sensor Simulation",id:"lidar-sensor-simulation",level:2},{value:"LIDAR Simulation in Gazebo",id:"lidar-simulation-in-gazebo",level:3},{value:"LIDAR Simulation in Unity",id:"lidar-simulation-in-unity",level:3},{value:"IMU and Inertial Sensor Simulation",id:"imu-and-inertial-sensor-simulation",level:2},{value:"IMU Simulation in Gazebo",id:"imu-simulation-in-gazebo",level:3},{value:"IMU Simulation in Unity",id:"imu-simulation-in-unity",level:3},{value:"Force/Torque Sensor Simulation",id:"forcetorque-sensor-simulation",level:2},{value:"Force/Torque Sensor Simulation in Gazebo",id:"forcetorque-sensor-simulation-in-gazebo",level:3},{value:"Force/Torque Sensor Simulation in Unity",id:"forcetorque-sensor-simulation-in-unity",level:3},{value:"Multi-Sensor Integration",id:"multi-sensor-integration",level:2},{value:"Sensor Synchronization in Unity",id:"sensor-synchronization-in-unity",level:3},{value:"Performance Optimization for Sensor Simulation",id:"performance-optimization-for-sensor-simulation",level:2},{value:"Adaptive Update Rates",id:"adaptive-update-rates",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,i.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"chapter-5-sensor-simulation-and-integration",children:"Chapter 5: Sensor Simulation and Integration"})}),"\n",(0,t.jsx)(e.h2,{id:"camera-sensor-simulation",children:"Camera Sensor Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Camera sensors are fundamental for humanoid robots, providing visual perception capabilities essential for navigation, object recognition, and environment understanding. Simulating camera sensors accurately in digital twin environments requires careful configuration of parameters to match physical sensors."}),"\n",(0,t.jsx)(e.h3,{id:"camera-simulation-in-gazebo",children:"Camera Simulation in Gazebo"}),"\n",(0,t.jsxs)(e.p,{children:["In Gazebo, camera sensors are defined using the ",(0,t.jsx)(e.code,{children:"<sensor>"}),' tag with type "camera". Here\'s a complete example:']}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Camera sensor definition in URDF/SDF --\x3e\r\n<gazebo reference="camera_link">\r\n  <sensor name="camera" type="camera">\r\n    <always_on>true</always_on>\r\n    <update_rate>30</update_rate>\r\n    <camera>\r\n      <horizontal_fov>1.047</horizontal_fov> \x3c!-- 60 degrees in radians --\x3e\r\n      <image>\r\n        <width>640</width>\r\n        <height>480</height>\r\n        <format>R8G8B8</format>\r\n      </image>\r\n      <clip>\r\n        <near>0.1</near>\r\n        <far>10.0</far>\r\n      </clip>\r\n      <noise>\r\n        <type>gaussian</type>\r\n        <mean>0.0</mean>\r\n        <stddev>0.007</stddev>\r\n      </noise>\r\n    </camera>\r\n    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\r\n      <frame_name>camera_optical_frame</frame_name>\r\n      <min_depth>0.1</min_depth>\r\n      <max_depth>10.0</max_depth>\r\n      <update_rate>30.0</update_rate>\r\n      <image_topic_name>/camera/image_raw</image_topic_name>\r\n      <camera_info_topic_name>/camera/camera_info</camera_info_topic_name>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,t.jsx)(e.h3,{id:"camera-simulation-in-unity",children:"Camera Simulation in Unity"}),"\n",(0,t.jsx)(e.p,{children:"In Unity, camera sensors are implemented using standard Unity cameras with ROS2 integration:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing Unity.Robotics.ROSTCPConnector.MessageTypes.Sensor;\r\n\r\npublic class CameraSensor : MonoBehaviour\r\n{\r\n    [Header("Camera Configuration")]\r\n    public Camera unityCamera;\r\n    public int width = 640;\r\n    public int height = 480;\r\n    public float updateRate = 30.0f;\r\n\r\n    [Header("ROS2 Configuration")]\r\n    public string imageTopic = "/camera/image_raw";\r\n    public string cameraInfoTopic = "/camera/camera_info";\r\n\r\n    private RenderTexture renderTexture;\r\n    private Texture2D texture2D;\r\n    private ROSConnection ros;\r\n    private float nextUpdate;\r\n\r\n    void Start()\r\n    {\r\n        // Initialize ROS connection\r\n        ros = ROSConnection.GetOrCreateInstance();\r\n\r\n        // Set up camera if not assigned\r\n        if (unityCamera == null)\r\n            unityCamera = GetComponent<Camera>();\r\n\r\n        // Create render texture for camera\r\n        SetupCamera();\r\n    }\r\n\r\n    void SetupCamera()\r\n    {\r\n        // Create render texture\r\n        renderTexture = new RenderTexture(width, height, 24);\r\n        unityCamera.targetTexture = renderTexture;\r\n\r\n        // Create texture2D for reading pixels\r\n        texture2D = new Texture2D(width, height, TextureFormat.RGB24, false);\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        if (Time.time >= nextUpdate)\r\n        {\r\n            CaptureAndPublishImage();\r\n            nextUpdate = Time.time + (1.0f / updateRate);\r\n        }\r\n    }\r\n\r\n    void CaptureAndPublishImage()\r\n    {\r\n        // Set active render texture\r\n        RenderTexture.active = renderTexture;\r\n\r\n        // Read pixels from render texture\r\n        texture2D.ReadPixels(new Rect(0, 0, width, height), 0, 0);\r\n        texture2D.Apply();\r\n\r\n        // Convert to ROS image message\r\n        var imageData = texture2D.GetRawTextureData<Color32>();\r\n\r\n        // Create and publish ROS image message\r\n        var rosImage = new Unity.Robotics.ROSTCPConnector.MessageTypes.Sensor.CompressedImageMsg\r\n        {\r\n            format = "jpeg",\r\n            data = imageData\r\n        };\r\n\r\n        ros.Publish(imageTopic, rosImage);\r\n    }\r\n\r\n    void OnDestroy()\r\n    {\r\n        if (renderTexture != null)\r\n            RenderTexture.ReleaseTemporary(renderTexture);\r\n        if (texture2D != null)\r\n            Destroy(texture2D);\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"lidar-sensor-simulation",children:"LIDAR Sensor Simulation"}),"\n",(0,t.jsx)(e.p,{children:"LIDAR sensors provide crucial 3D spatial information for navigation and mapping. Simulating LIDAR in digital twin environments requires accurate raycasting and point cloud generation."}),"\n",(0,t.jsx)(e.h3,{id:"lidar-simulation-in-gazebo",children:"LIDAR Simulation in Gazebo"}),"\n",(0,t.jsx)(e.p,{children:"Gazebo provides several LIDAR sensor types, from simple 2D to complex 3D sensors:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'\x3c!-- 2D LIDAR sensor --\x3e\r\n<gazebo reference="lidar_link">\r\n  <sensor name="lidar_2d" type="ray">\r\n    <always_on>true</always_on>\r\n    <update_rate>10</update_rate>\r\n    <ray>\r\n      <scan>\r\n        <horizontal>\r\n          <samples>720</samples>\r\n          <resolution>1</resolution>\r\n          <min_angle>-3.14159</min_angle> \x3c!-- -180 degrees --\x3e\r\n          <max_angle>3.14159</max_angle>    \x3c!-- 180 degrees --\x3e\r\n        </horizontal>\r\n      </scan>\r\n      <range>\r\n        <min>0.1</min>\r\n        <max>30.0</max>\r\n        <resolution>0.01</resolution>\r\n      </range>\r\n    </ray>\r\n    <plugin name="lidar_2d_controller" filename="libgazebo_ros_laser.so">\r\n      <frame_name>lidar_frame</frame_name>\r\n      <topic_name>/scan</topic_name>\r\n      <update_rate>10</update_rate>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\r\n\r\n\x3c!-- 3D LIDAR sensor (Velodyne-style) --\x3e\r\n<gazebo reference="velodyne_link">\r\n  <sensor name="velodyne_3d" type="ray">\r\n    <always_on>true</always_on>\r\n    <update_rate>10</update_rate>\r\n    <ray>\r\n      <scan>\r\n        <horizontal>\r\n          <samples>1024</samples>\r\n          <resolution>1</resolution>\r\n          <min_angle>-3.14159</min_angle>\r\n          <max_angle>3.14159</max_angle>\r\n        </horizontal>\r\n        <vertical>\r\n          <samples>32</samples>\r\n          <resolution>1</resolution>\r\n          <min_angle>-0.5236</min_angle> \x3c!-- -30 degrees --\x3e\r\n          <max_angle>0.2618</max_angle>   \x3c!-- 15 degrees --\x3e\r\n        </vertical>\r\n      </scan>\r\n      <range>\r\n        <min>0.1</min>\r\n        <max>100.0</max>\r\n        <resolution>0.01</resolution>\r\n      </range>\r\n    </ray>\r\n    <plugin name="velodyne_controller" filename="libgazebo_ros_velodyne_laser.so">\r\n      <frame_name>velodyne_frame</frame_name>\r\n      <topic_name>/velodyne_points</topic_name>\r\n      <min_range>0.1</min_range>\r\n      <max_range>100.0</max_range>\r\n      <gaussian_noise>0.01</gaussian_noise>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,t.jsx)(e.h3,{id:"lidar-simulation-in-unity",children:"LIDAR Simulation in Unity"}),"\n",(0,t.jsx)(e.p,{children:"In Unity, LIDAR simulation is implemented using raycasting:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing Unity.Robotics.ROSTCPConnector.MessageTypes.Sensor;\r\n\r\npublic class LIDARSensor : MonoBehaviour\r\n{\r\n    [Header("LIDAR Configuration")]\r\n    public float minRange = 0.1f;\r\n    public float maxRange = 30.0f;\r\n    public int horizontalSamples = 720;\r\n    public float horizontalFOV = 360f;\r\n    public int verticalSamples = 1;\r\n    public float verticalFOV = 0f;\r\n    public float updateRate = 10.0f;\r\n\r\n    [Header("ROS2 Configuration")]\r\n    public string topicName = "/scan";\r\n\r\n    private ROSConnection ros;\r\n    private float nextUpdate;\r\n    private RaycastHit[] raycastHits;\r\n\r\n    void Start()\r\n    {\r\n        ros = ROSConnection.GetOrCreateInstance();\r\n        raycastHits = new RaycastHit[horizontalSamples * verticalSamples];\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        if (Time.time >= nextUpdate)\r\n        {\r\n            PublishLIDARData();\r\n            nextUpdate = Time.time + (1.0f / updateRate);\r\n        }\r\n    }\r\n\r\n    void PublishLIDARData()\r\n    {\r\n        var ranges = new float[horizontalSamples * verticalSamples];\r\n\r\n        // Calculate angles\r\n        float horizontalStep = horizontalFOV / horizontalSamples;\r\n        float verticalStep = verticalFOV / verticalSamples;\r\n\r\n        for (int v = 0; v < verticalSamples; v++)\r\n        {\r\n            for (int h = 0; h < horizontalSamples; h++)\r\n            {\r\n                float hAngle = (h * horizontalStep - horizontalFOV / 2) * Mathf.Deg2Rad;\r\n                float vAngle = (v * verticalStep - verticalFOV / 2) * Mathf.Deg2Rad;\r\n\r\n                // Calculate ray direction\r\n                Vector3 direction = CalculateLIDARDirection(hAngle, vAngle);\r\n\r\n                // Perform raycast\r\n                if (Physics.Raycast(transform.position, direction, out RaycastHit hit, maxRange))\r\n                {\r\n                    ranges[v * horizontalSamples + h] = hit.distance;\r\n                }\r\n                else\r\n                {\r\n                    ranges[v * horizontalSamples + h] = maxRange;\r\n                }\r\n            }\r\n        }\r\n\r\n        // Create and publish ROS LaserScan message\r\n        var laserScan = new Unity.Robotics.ROSTCPConnector.MessageTypes.Sensor.LaserScanMsg\r\n        {\r\n            header = new Unity.Robotics.ROSTCPConnector.MessageTypes.Std.HeaderMsg\r\n            {\r\n                stamp = new Unity.Robotics.ROSTCPConnector.MessageTypes.Std.TimeMsg\r\n                {\r\n                    sec = (int)Time.time,\r\n                    nanosec = (uint)((Time.time - Mathf.Floor(Time.time)) * 1e9f)\r\n                },\r\n                frame_id = transform.name\r\n            },\r\n            angle_min = -horizontalFOV * Mathf.Deg2Rad / 2,\r\n            angle_max = horizontalFOV * Mathf.Deg2Rad / 2,\r\n            angle_increment = (horizontalFOV * Mathf.Deg2Rad) / horizontalSamples,\r\n            time_increment = 0,\r\n            scan_time = 1.0f / updateRate,\r\n            range_min = minRange,\r\n            range_max = maxRange,\r\n            ranges = ranges,\r\n            intensities = new float[ranges.Length] // Intensity data (optional)\r\n        };\r\n\r\n        ros.Publish(topicName, laserScan);\r\n    }\r\n\r\n    Vector3 CalculateLIDARDirection(float hAngle, float vAngle)\r\n    {\r\n        // Convert spherical coordinates to Cartesian\r\n        Vector3 direction = new Vector3(\r\n            Mathf.Cos(vAngle) * Mathf.Cos(hAngle),\r\n            Mathf.Cos(vAngle) * Mathf.Sin(hAngle),\r\n            Mathf.Sin(vAngle)\r\n        );\r\n\r\n        // Apply transform rotation\r\n        return transform.TransformDirection(direction);\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"imu-and-inertial-sensor-simulation",children:"IMU and Inertial Sensor Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Inertial Measurement Units (IMUs) provide crucial orientation, acceleration, and angular velocity data for humanoid robot control and navigation."}),"\n",(0,t.jsx)(e.h3,{id:"imu-simulation-in-gazebo",children:"IMU Simulation in Gazebo"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'\x3c!-- IMU sensor definition --\x3e\r\n<gazebo reference="imu_link">\r\n  <sensor name="imu_sensor" type="imu">\r\n    <always_on>true</always_on>\r\n    <update_rate>100</update_rate>\r\n    <visualize>false</visualize>\r\n    <imu>\r\n      <angular_velocity>\r\n        <x>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>2e-4</stddev>\r\n            <bias_mean>0.0000075</bias_mean>\r\n            <bias_stddev>0.0000008</bias_stddev>\r\n          </noise>\r\n        </x>\r\n        <y>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>2e-4</stddev>\r\n            <bias_mean>0.0000075</bias_mean>\r\n            <bias_stddev>0.0000008</bias_stddev>\r\n          </noise>\r\n        </y>\r\n        <z>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>2e-4</stddev>\r\n            <bias_mean>0.0000075</bias_mean>\r\n            <bias_stddev>0.0000008</bias_stddev>\r\n          </noise>\r\n        </z>\r\n      </angular_velocity>\r\n      <linear_acceleration>\r\n        <x>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>1.7e-2</stddev>\r\n            <bias_mean>0.1</bias_mean>\r\n            <bias_stddev>0.001</bias_stddev>\r\n          </noise>\r\n        </x>\r\n        <y>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>1.7e-2</stddev>\r\n            <bias_mean>0.1</bias_mean>\r\n            <bias_stddev>0.001</bias_stddev>\r\n          </noise>\r\n        </y>\r\n        <z>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>1.7e-2</stddev>\r\n            <bias_mean>0.1</bias_mean>\r\n            <bias_stddev>0.001</bias_stddev>\r\n          </noise>\r\n        </z>\r\n      </linear_acceleration>\r\n    </imu>\r\n    <plugin name="imu_controller" filename="libgazebo_ros_imu.so">\r\n      <frame_name>imu_link</frame_name>\r\n      <topic_name>/imu/data</topic_name>\r\n      <serviceName>/imu/service</serviceName>\r\n      <gaussianNoise>0.0017</gaussianNoise>\r\n      <updateRateHZ>100.0</updateRateHZ>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,t.jsx)(e.h3,{id:"imu-simulation-in-unity",children:"IMU Simulation in Unity"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing Unity.Robotics.ROSTCPConnector.MessageTypes.Sensor;\r\n\r\npublic class IMUSensor : MonoBehaviour\r\n{\r\n    [Header("IMU Configuration")]\r\n    public float updateRate = 100.0f;\r\n    public float noiseLevel = 0.001f;\r\n\r\n    [Header("Noise Parameters")]\r\n    public Vector3 angularVelocityNoise = new Vector3(2e-4f, 2e-4f, 2e-4f);\r\n    public Vector3 linearAccelerationNoise = new Vector3(1.7e-2f, 1.7e-2f, 1.7e-2f);\r\n\r\n    [Header("ROS2 Configuration")]\r\n    public string topicName = "/imu/data";\r\n\r\n    private ROSConnection ros;\r\n    private float nextUpdate;\r\n    private Rigidbody robotRigidbody;\r\n\r\n    void Start()\r\n    {\r\n        ros = ROSConnection.GetOrCreateInstance();\r\n\r\n        // Try to get rigidbody for more accurate IMU simulation\r\n        robotRigidbody = GetComponentInParent<Rigidbody>();\r\n        if (robotRigidbody == null)\r\n            robotRigidbody = GetComponent<Rigidbody>();\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        if (Time.time >= nextUpdate)\r\n        {\r\n            PublishIMUData();\r\n            nextUpdate = Time.time + (1.0f / updateRate);\r\n        }\r\n    }\r\n\r\n    void PublishIMUData()\r\n    {\r\n        // Get orientation (quaternion)\r\n        Quaternion orientation = transform.rotation;\r\n\r\n        // Get angular velocity (if rigidbody is available)\r\n        Vector3 angularVelocity = Vector3.zero;\r\n        if (robotRigidbody != null)\r\n        {\r\n            angularVelocity = transform.InverseTransformDirection(robotRigidbody.angularVelocity);\r\n        }\r\n        else\r\n        {\r\n            // Approximate angular velocity from rotation change\r\n            angularVelocity = GetApproximateAngularVelocity();\r\n        }\r\n\r\n        // Get linear acceleration\r\n        Vector3 linearAcceleration = GetLinearAcceleration();\r\n\r\n        // Add noise to measurements\r\n        angularVelocity += AddNoise(angularVelocityNoise);\r\n        linearAcceleration += AddNoise(linearAccelerationNoise);\r\n\r\n        // Create and publish ROS IMU message\r\n        var imuMsg = new Unity.Robotics.ROSTCPConnector.MessageTypes.Sensor.ImuMsg\r\n        {\r\n            header = new Unity.Robotics.ROSTCPConnector.MessageTypes.Std.HeaderMsg\r\n            {\r\n                stamp = new Unity.Robotics.ROSTCPConnector.MessageTypes.Std.TimeMsg\r\n                {\r\n                    sec = (int)Time.time,\r\n                    nanosec = (uint)((Time.time - Mathf.Floor(Time.time)) * 1e9f)\r\n                },\r\n                frame_id = transform.name\r\n            },\r\n            orientation = new Unity.Robotics.ROSTCPConnector.MessageTypes.Geometry.QuaternionMsg\r\n            {\r\n                x = orientation.x,\r\n                y = orientation.y,\r\n                z = orientation.z,\r\n                w = orientation.w\r\n            },\r\n            angular_velocity = new Unity.Robotics.ROSTCPConnector.MessageTypes.Geometry.Vector3Msg\r\n            {\r\n                x = angularVelocity.x,\r\n                y = angularVelocity.y,\r\n                z = angularVelocity.z\r\n            },\r\n            linear_acceleration = new Unity.Robotics.ROSTCPConnector.MessageTypes.Geometry.Vector3Msg\r\n            {\r\n                x = linearAcceleration.x,\r\n                y = linearAcceleration.y,\r\n                z = linearAcceleration.z\r\n            }\r\n        };\r\n\r\n        ros.Publish(topicName, imuMsg);\r\n    }\r\n\r\n    Vector3 GetApproximateAngularVelocity()\r\n    {\r\n        // This is a simplified approximation\r\n        // In a real implementation, you\'d track rotation over time\r\n        return new Vector3(\r\n            Random.Range(-0.01f, 0.01f),\r\n            Random.Range(-0.01f, 0.01f),\r\n            Random.Range(-0.01f, 0.01f)\r\n        );\r\n    }\r\n\r\n    Vector3 GetLinearAcceleration()\r\n    {\r\n        Vector3 acceleration = Vector3.zero;\r\n\r\n        if (robotRigidbody != null)\r\n        {\r\n            // Calculate acceleration from velocity change\r\n            // In practice, this would require storing previous velocity\r\n            acceleration = transform.InverseTransformDirection(robotRigidbody.velocity);\r\n        }\r\n        else\r\n        {\r\n            // Use gravity and any applied forces\r\n            acceleration = Physics.gravity;\r\n        }\r\n\r\n        return acceleration;\r\n    }\r\n\r\n    Vector3 AddNoise(Vector3 noiseLevels)\r\n    {\r\n        return new Vector3(\r\n            Random.Range(-noiseLevels.x, noiseLevels.x),\r\n            Random.Range(-noiseLevels.y, noiseLevels.y),\r\n            Random.Range(-noiseLevels.z, noiseLevels.z)\r\n        );\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"forcetorque-sensor-simulation",children:"Force/Torque Sensor Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Force/torque sensors are essential for humanoid robots to detect contact forces and enable safe interaction with the environment."}),"\n",(0,t.jsx)(e.h3,{id:"forcetorque-sensor-simulation-in-gazebo",children:"Force/Torque Sensor Simulation in Gazebo"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Force/Torque sensor in a joint --\x3e\r\n<gazebo reference="left_foot_joint">\r\n  <sensor name="left_foot_ft_sensor" type="force_torque">\r\n    <always_on>true</always_on>\r\n    <update_rate>100</update_rate>\r\n    <force_torque>\r\n      <frame>sensor</frame>\r\n      <measure_direction>from_parent_link</measure_direction>\r\n    </force_torque>\r\n    <plugin name="ft_sensor_controller" filename="libgazebo_ros_ft_sensor.so">\r\n      <frame_name>left_foot_link</frame_name>\r\n      <topic_name>/left_foot/ft_sensor</topic_name>\r\n      <update_rate>100.0</update_rate>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,t.jsx)(e.h3,{id:"forcetorque-sensor-simulation-in-unity",children:"Force/Torque Sensor Simulation in Unity"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing Unity.Robotics.ROSTCPConnector.MessageTypes.Geometry;\r\n\r\npublic class ForceTorqueSensor : MonoBehaviour\r\n{\r\n    [Header("Sensor Configuration")]\r\n    public float updateRate = 100.0f;\r\n    public float noiseLevel = 0.1f;\r\n\r\n    [Header("ROS2 Configuration")]\r\n    public string topicName = "/ft_sensor";\r\n\r\n    private ROSConnection ros;\r\n    private float nextUpdate;\r\n    private Collider sensorCollider;\r\n    private ContactPoint[] contacts = new ContactPoint[10];\r\n    private int contactCount = 0;\r\n\r\n    void Start()\r\n    {\r\n        ros = ROSConnection.GetOrCreateInstance();\r\n        sensorCollider = GetComponent<Collider>();\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        if (Time.time >= nextUpdate)\r\n        {\r\n            PublishForceTorqueData();\r\n            nextUpdate = Time.time + (1.0f / updateRate);\r\n        }\r\n    }\r\n\r\n    void PublishForceTorqueData()\r\n    {\r\n        // Calculate forces from contacts\r\n        Vector3 totalForce = Vector3.zero;\r\n        Vector3 totalTorque = Vector3.zero;\r\n\r\n        // Get contact information (this would need to be updated based on actual contacts)\r\n        totalForce = CalculateContactForce();\r\n        totalTorque = CalculateContactTorque(totalForce);\r\n\r\n        // Add noise to measurements\r\n        totalForce += new Vector3(\r\n            Random.Range(-noiseLevel, noiseLevel),\r\n            Random.Range(-noiseLevel, noiseLevel),\r\n            Random.Range(-noiseLevel, noiseLevel)\r\n        );\r\n\r\n        totalTorque += new Vector3(\r\n            Random.Range(-noiseLevel, noiseLevel),\r\n            Random.Range(-noiseLevel, noiseLevel),\r\n            Random.Range(-noiseLevel, noiseLevel)\r\n        );\r\n\r\n        // Create and publish ROS Wrench message\r\n        var wrenchMsg = new Unity.Robotics.ROSTCPConnector.MessageTypes.Geometry.WrenchMsg\r\n        {\r\n            force = new Unity.Robotics.ROSTCPConnector.MessageTypes.Geometry.Vector3Msg\r\n            {\r\n                x = totalForce.x,\r\n                y = totalForce.y,\r\n                z = totalForce.z\r\n            },\r\n            torque = new Unity.Robotics.ROSTCPConnector.MessageTypes.Geometry.Vector3Msg\r\n            {\r\n                x = totalTorque.x,\r\n                y = totalTorque.y,\r\n                z = totalTorque.z\r\n            }\r\n        };\r\n\r\n        ros.Publish(topicName, wrenchMsg);\r\n    }\r\n\r\n    Vector3 CalculateContactForce()\r\n    {\r\n        // In a real implementation, this would calculate force from actual contacts\r\n        // For simulation, we\'ll use a simplified approach\r\n        var colliders = Physics.OverlapBox(transform.position, sensorCollider.bounds.extents);\r\n\r\n        Vector3 totalForce = Vector3.zero;\r\n        foreach (var collider in colliders)\r\n        {\r\n            if (collider.gameObject != gameObject)\r\n            {\r\n                // Calculate contact force based on collision\r\n                totalForce += Physics.gravity * 0.1f; // Simplified\r\n            }\r\n        }\r\n\r\n        return totalForce;\r\n    }\r\n\r\n    Vector3 CalculateContactTorque(Vector3 force)\r\n    {\r\n        // Calculate torque as cross product of position and force\r\n        return Vector3.Cross(transform.position, force);\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"multi-sensor-integration",children:"Multi-Sensor Integration"}),"\n",(0,t.jsx)(e.p,{children:"Integrating multiple sensors requires careful synchronization and data fusion to provide coherent perception capabilities."}),"\n",(0,t.jsx)(e.h3,{id:"sensor-synchronization-in-unity",children:"Sensor Synchronization in Unity"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing System.Collections.Generic;\r\n\r\npublic class MultiSensorFusion : MonoBehaviour\r\n{\r\n    [Header("Sensor Components")]\r\n    public List<SensorBase> sensors = new List<SensorBase>();\r\n\r\n    [Header("Synchronization")]\r\n    public float synchronizationWindow = 0.01f; // 10ms window\r\n\r\n    private Dictionary<string, SensorData> latestSensorData = new Dictionary<string, SensorData>();\r\n    private float lastSyncTime;\r\n\r\n    void Start()\r\n    {\r\n        InitializeSensors();\r\n    }\r\n\r\n    void InitializeSensors()\r\n    {\r\n        // Find all sensor components attached to this robot\r\n        var sensorComponents = GetComponentsInChildren<SensorBase>();\r\n        foreach (var sensor in sensorComponents)\r\n        {\r\n            sensors.Add(sensor);\r\n            latestSensorData[sensor.GetSensorId()] = new SensorData();\r\n        }\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        CheckSynchronization();\r\n    }\r\n\r\n    void CheckSynchronization()\r\n    {\r\n        // Check if all sensors have updated within the synchronization window\r\n        bool allUpdated = true;\r\n        float currentTime = Time.time;\r\n\r\n        foreach (var sensor in sensors)\r\n        {\r\n            if (currentTime - sensor.LastUpdateTime > synchronizationWindow)\r\n            {\r\n                allUpdated = false;\r\n                break;\r\n            }\r\n        }\r\n\r\n        if (allUpdated && currentTime - lastSyncTime > synchronizationWindow)\r\n        {\r\n            // All sensors are synchronized, perform fusion\r\n            PerformSensorFusion();\r\n            lastSyncTime = currentTime;\r\n        }\r\n    }\r\n\r\n    void PerformSensorFusion()\r\n    {\r\n        // Example: Combine IMU and camera data for better pose estimation\r\n        var imuData = GetLatestSensorData("IMU");\r\n        var cameraData = GetLatestSensorData("Camera");\r\n\r\n        if (imuData != null && cameraData != null)\r\n        {\r\n            // Perform sensor fusion algorithm\r\n            var fusedPose = FuseIMUCameraData(imuData, cameraData);\r\n\r\n            // Publish fused data\r\n            PublishFusedData(fusedPose);\r\n        }\r\n    }\r\n\r\n    SensorData GetLatestSensorData(string sensorType)\r\n    {\r\n        foreach (var pair in latestSensorData)\r\n        {\r\n            if (pair.Key.Contains(sensorType))\r\n            {\r\n                return pair.Value;\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n\r\n    Pose FuseIMUCameraData(SensorData imuData, SensorData cameraData)\r\n    {\r\n        // Simplified sensor fusion algorithm\r\n        // In practice, this would use more sophisticated methods like Kalman filtering\r\n        return new Pose(Vector3.zero, Quaternion.identity);\r\n    }\r\n\r\n    void PublishFusedData(Pose fusedPose)\r\n    {\r\n        // Publish the fused sensor data to ROS2 or other systems\r\n        Debug.Log($"Publishing fused pose: {fusedPose}");\r\n    }\r\n}\r\n\r\npublic abstract class SensorBase : MonoBehaviour\r\n{\r\n    public string sensorId;\r\n    public float LastUpdateTime { get; protected set; }\r\n\r\n    public string GetSensorId()\r\n    {\r\n        return sensorId;\r\n    }\r\n\r\n    protected virtual void Start()\r\n    {\r\n        LastUpdateTime = Time.time;\r\n    }\r\n}\r\n\r\n[System.Serializable]\r\npublic class SensorData\r\n{\r\n    public float timestamp;\r\n    public object data;\r\n    public string sensorType;\r\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"performance-optimization-for-sensor-simulation",children:"Performance Optimization for Sensor Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Simulating multiple sensors can be computationally expensive. Here are optimization techniques:"}),"\n",(0,t.jsx)(e.h3,{id:"adaptive-update-rates",children:"Adaptive Update Rates"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"using UnityEngine;\r\n\r\npublic class AdaptiveSensorUpdater : MonoBehaviour\r\n{\r\n    public enum SensorPriority\r\n    {\r\n        Critical,     // High update rate (100Hz+)\r\n        Standard,     // Medium update rate (30Hz)\r\n        LowPriority   // Low update rate (10Hz)\r\n    }\r\n\r\n    [System.Serializable]\r\n    public class SensorConfiguration\r\n    {\r\n        public SensorBase sensor;\r\n        public SensorPriority priority;\r\n        public float baseUpdateRate;\r\n        public float minUpdateRate;\r\n        public float maxUpdateRate;\r\n    }\r\n\r\n    public List<SensorConfiguration> sensorConfigs = new List<SensorConfiguration>();\r\n\r\n    void Start()\r\n    {\r\n        SetupAdaptiveUpdateRates();\r\n    }\r\n\r\n    void SetupAdaptiveUpdateRates()\r\n    {\r\n        foreach (var config in sensorConfigs)\r\n        {\r\n            // Set initial update rates based on priority\r\n            switch (config.priority)\r\n            {\r\n                case SensorPriority.Critical:\r\n                    config.baseUpdateRate = 100f;\r\n                    config.minUpdateRate = 50f;\r\n                    config.maxUpdateRate = 200f;\r\n                    break;\r\n                case SensorPriority.Standard:\r\n                    config.baseUpdateRate = 30f;\r\n                    config.minUpdateRate = 10f;\r\n                    config.maxUpdateRate = 60f;\r\n                    break;\r\n                case SensorPriority.LowPriority:\r\n                    config.baseUpdateRate = 10f;\r\n                    config.minUpdateRate = 5f;\r\n                    config.maxUpdateRate = 30f;\r\n                    break;\r\n            }\r\n        }\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        // Adjust update rates based on system performance\r\n        AdjustUpdateRates();\r\n    }\r\n\r\n    void AdjustUpdateRates()\r\n    {\r\n        float performanceFactor = CalculatePerformanceFactor();\r\n\r\n        foreach (var config in sensorConfigs)\r\n        {\r\n            float adjustedRate = config.baseUpdateRate * performanceFactor;\r\n            adjustedRate = Mathf.Clamp(adjustedRate, config.minUpdateRate, config.maxUpdateRate);\r\n\r\n            // Apply rate to sensor (implementation depends on sensor type)\r\n            if (config.sensor is CameraSensor camSensor)\r\n            {\r\n                camSensor.updateRate = adjustedRate;\r\n            }\r\n            else if (config.sensor is LIDARSensor lidarSensor)\r\n            {\r\n                lidarSensor.updateRate = adjustedRate;\r\n            }\r\n        }\r\n    }\r\n\r\n    float CalculatePerformanceFactor()\r\n    {\r\n        // Calculate performance factor based on frame rate\r\n        float targetFrameRate = 60f;\r\n        float currentFrameRate = 1f / Time.deltaTime;\r\n        return Mathf.Clamp01(currentFrameRate / targetFrameRate);\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,t.jsx)(e.p,{children:"Sensor simulation is a critical component of digital twin systems for humanoid robots, providing the perception capabilities necessary for autonomous operation. Accurate simulation of cameras, LIDAR, IMU, and force/torque sensors ensures that control algorithms and perception systems can be thoroughly tested in virtual environments before deployment on physical robots. Proper configuration of sensor parameters, noise models, and update rates is essential for achieving realistic simulation that closely matches physical sensor behavior."})]})}function m(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453(n,e,r){r.d(e,{R:()=>o,x:()=>s});var a=r(6540);const t={},i=a.createContext(t);function o(n){const e=a.useContext(i);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),a.createElement(i.Provider,{value:e},n.children)}}}]);